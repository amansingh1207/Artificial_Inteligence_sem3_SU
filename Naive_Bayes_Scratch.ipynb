{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d76ca56",
   "metadata": {},
   "source": [
    "# Naive Bayes Implementation from Scratch\n",
    "---\n",
    "This notebook follows the GeeksforGeeks tutorial and implements **Naive Bayes** from scratch using **Gaussian Distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94daa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_class(mydata):\n",
    "    classes = []\n",
    "    for i in range(len(mydata)):\n",
    "        if mydata[i][-1] not in classes:\n",
    "            classes.append(mydata[i][-1])\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(mydata)):\n",
    "            if mydata[j][-1] == classes[i]:\n",
    "                mydata[j][-1] = i\n",
    "    return mydata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def splitting(mydata, ratio):\n",
    "    train_num = int(len(mydata) * ratio)\n",
    "    train = []\n",
    "    test = list(mydata)\n",
    "    while len(train) < train_num:\n",
    "        index = random.randrange(len(test))\n",
    "        train.append(test.pop(index))\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def groupUnderClass(mydata):\n",
    "    data_dict = {}\n",
    "    for i in range(len(mydata)):\n",
    "        if mydata[i][-1] not in data_dict:\n",
    "            data_dict[mydata[i][-1]] = []\n",
    "        data_dict[mydata[i][-1]].append(mydata[i])\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MeanAndStdDev(numbers):\n",
    "    avg = np.mean(numbers)\n",
    "    stddev = np.std(numbers)\n",
    "    return avg, stddev\n",
    "\n",
    "def MeanAndStdDevForClass(mydata):\n",
    "    info = {}\n",
    "    data_dict = groupUnderClass(mydata)\n",
    "    for classValue, instances in data_dict.items():\n",
    "        info[classValue] = [MeanAndStdDev(attribute) for attribute in zip(*instances)]\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4800e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateGaussianProbability(x, mean, stdev):\n",
    "    epsilon = 1e-10\n",
    "    expo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev + epsilon, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * (stdev + epsilon))) * expo\n",
    "\n",
    "def calculateClassProbabilities(info, test):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in info.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, std_dev = classSummaries[i]\n",
    "            x = test[i]\n",
    "            probabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe0baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(info, test):\n",
    "    probabilities = calculateClassProbabilities(info, test)\n",
    "    bestLabel = max(probabilities, key=probabilities.get)\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(info, test):\n",
    "    predictions = [predict(info, instance) for instance in test]\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy_rate(test, predictions):\n",
    "    correct = sum(1 for i in range(len(test)) if test[i][-1] == predictions[i])\n",
    "    return (correct / float(len(test))) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8499f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from io import StringIO\n",
    "\n",
    "data = StringIO(\"\"\"\n",
    "2,50,5,1\n",
    "0,30,1,0\n",
    "3,80,10,1\n",
    "1,45,3,0\n",
    "4,90,15,1\n",
    "0,25,0,0\n",
    "1,70,5,1\n",
    "0,20,1,0\n",
    "3,85,8,1\n",
    "1,40,2,0\n",
    "\"\"\")\n",
    "\n",
    "df = pd.read_csv(data, header=None)\n",
    "mydata = df.values.tolist()\n",
    "mydata = encode_class(mydata)\n",
    "\n",
    "for i in range(len(mydata)):\n",
    "    for j in range(len(mydata[i]) - 1):\n",
    "        mydata[i][j] = float(mydata[i][j])\n",
    "\n",
    "ratio = 0.7\n",
    "train_data, test_data = splitting(mydata, ratio)\n",
    "\n",
    "print('Total number of examples:', len(mydata))\n",
    "print('Training examples:', len(train_data))\n",
    "print('Test examples:', len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed9ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info = MeanAndStdDevForClass(train_data)\n",
    "predictions = getPredictions(info, test_data)\n",
    "accuracy = accuracy_rate(test_data, predictions)\n",
    "print('Accuracy of the model:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true = [row[-1] for row in test_data]\n",
    "y_pred = predictions\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d058628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1 Score']\n",
    "values = [precision, recall, f1]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(metrics, values, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "plt.ylim(0,1)\n",
    "plt.title('Precision, Recall, and F1 Score')\n",
    "plt.ylabel('Score')\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}